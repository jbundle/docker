version: "3.7"
services:
  # The environment variable "ELASTIC_VERSION" is used throughout this file to
  # specify the version of the images to run. The default is set in the
  # '.env' file in this folder. It can be overridden with any normal
  # technique for setting environment variables, for example:
  #
  #   ELASTIC_VERSION=5.5.1 docker-compose up
  #
  # Additionally, the user can control:
  #   * the total memory assigned to the ES container through the variable ES_MEM_LIMIT e.g. ES_MEM_LIMIT=2g
  #   * the memory assigned to the ES JVM through the variable ES_JVM_HEAP e.g. ES_JVM_SIZE=1024m
  #   * the password used for the elastic, logstash_system and kibana accounts through the variable ES_PASSWORD
  #   * the mysql root password through the var MYSQL_ROOT_PASSWORD
  #   * the default index pattern used in kibana via the var DEFAULT_INDEX_PATTERN
  #   * the ES heap size through tt
  # REF: https://docs.docker.com/compose/compose-file/#variable-substitution
  #

  #Elasticsearch container
  elasticsearch:
#    container_name: elasticsearch
    hostname: elasticsearch
    image: "docker.elastic.co/elasticsearch/elasticsearch:${ELASTIC_VERSION:-5.5.1}"
    environment:
      - http.host=0.0.0.0
      - transport.host=127.0.0.1
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms${ES_JVM_HEAP:-1024m} -Xmx${ES_JVM_HEAP:-1024m}"
#    mem_limit: ${ES_MEM_LIMIT:-2g}
#    ulimits:
#      memlock:
#        soft: -1
#        hard: -1
    configs:
    - source: elastic_config
      target: /usr/share/elasticsearch/elasticsearch.yml
    volumes:
    - elasticsearch-data:/usr/share/elasticsearch/data

    #Port 9200 is available on the host. Need to for user to access as well as Packetbeat
    ports: ['9200:9200']
    #Healthcheck to confirm availability of ES. Other containers wait on this.
    healthcheck:
      test: ["CMD", "curl","-s" ,"-f", "-u", "elastic:${ES_PASSWORD:-changeme}", "http://localhost:9200/_cat/health"]
    #Internal network for the containers
    networks:
    - logging
    - proxy
    deploy:
      mode: replicated
      replicas: 1
      restart_policy:
        condition: on-failure
      labels:
      - com.df.distribute=true
      - com.df.notify=true
      - com.df.port=80
      - com.df.httpsOnly=true
      - com.df.serviceDomain=elasticsearch.docker.usc.edu
      - com.df.alertName=memlimit
      - com.df.alertIf=@service_mem_limit:0.8
      - com.df.alertFor=30s
      resources:
        reservations:
          memory: ${ES_MEM_LIMIT:-2g}
        limits:
          memory: ${ES_MEM_LIMIT:-2g}

  #Kibana container
  kibana:
#    container_name: kibana
    hostname: kibana
    image: "docker.elastic.co/kibana/kibana:${ELASTIC_VERSION:-5.5.1}"
    configs:
    - source: kibana_config
      target: /usr/share/kibana/kibana.yml
    #Port 5601 accessible on the host
    ports: ['5601:5601']
    networks:
    - logging
    - proxy
    #We don't start Kibana until the ES instance is ready
    depends_on:
    - elasticsearch
    environment:
      - "ELASTICSEARCH_PASSWORD=${ES_PASSWORD:-changeme}"
    healthcheck:
      test: ["CMD", "curl", "-s", "-f", "http://localhost:5601/login"]
      retries: 6
    deploy:
      mode: replicated
      replicas: 1
      restart_policy:
        condition: on-failure
      labels:
      - com.df.distribute=true
      - com.df.notify=true
      - com.df.serviceDomain.1=${ELK_SUB_DOMAIN:-elk}.${DOMAIN_NAME:-docker.usc.edu}
      - com.df.port.1=5601
      - com.df.xForwardedProto.1=true
      - com.df.httpsOnly.1=true
      - com.df.servicePath.2=${ELK_PATH:-/elk}
      - com.df.port.2=5601
      - com.df.reqPathSearchReplace.2=${ELK_PATH:-/elk},/
      - com.df.xForwardedProto.2=true
      - com.df.httpsOnly.2=true
      - com.df.serviceDomain.3=${KIBANA_SUB_DOMAIN:-kibana}.${DOMAIN_NAME:-docker.usc.edu}
      - com.df.port.3=5601
      - com.df.xForwardedProto.3=true
      - com.df.httpsOnly.3=true
      - com.df.servicePath.4=${KIBANA_PATH:-/kibana}
      - com.df.port.4=5601
      - com.df.reqPathSearchReplace.4=${KIBANA_PATH:-/kibana},/
      - com.df.xForwardedProto.4=true
      - com.df.httpsOnly.4=true
#      - com.df.servicePath=/app,/elasticsearch,/api,/ui,/bundles,/plugins,/status,/es_admin
      - com.df.alertName=memlimit
      - com.df.alertIf=@service_mem_limit:0.8
      - com.df.alertFor=30s
      resources:
        reservations:
          memory: 256m
        limits:
          memory: 512m

  #Heartbeat container
  heartbeat:
#    container_name: heartbeat
    hostname: heartbeat
    image: "docker.elastic.co/beats/heartbeat:${ELASTIC_VERSION:-5.5.1}"
#    volumes:
      #Mount the heartbeat configuration so users can make edits
    configs:
    - source: heartbeat_config
      target: /usr/share/heartbeat/heartbeat.yml
    depends_on:
      - elasticsearch
#      :  { condition: service_healthy }
    environment:
      - "ES_PASSWORD=${ES_PASSWORD:-changeme}"
    command: heartbeat -e -E output.elasticsearch.username=elastic -E output.elasticsearch.password=${ES_PASSWORD:-changeme} -strict.perms=false
    networks:
    - logging
#    restart: on-failure
    deploy:
      mode: replicated
      replicas: 1
      restart_policy:
        condition: on-failure
      labels:
      - com.df.distribute=true
      - com.df.notify=true
      - com.df.port=80
      - com.df.alertName=memlimit
      - com.df.alertIf=@service_mem_limit:0.8
      - com.df.alertFor=30s

  #Filebeat container
  filebeat:
#    container_name: filebeat
    hostname: filebeat
    user: root
    image: "docker.elastic.co/beats/filebeat:${ELASTIC_VERSION:-5.5.1}"
    configs:
    #Mount the filebeat configuration so users can make edit
    - source: filebeat_config
      target: /usr/share/filebeat/filebeat.yml
    #Mount the prospectors directory. Users can in turn add propspectors to this directory and they will be dynamically loaded
    - source: prospectors_config
      target: /usr/share/filebeat/prospectors.d/docker.yml
    volumes:
      #Mount the hosts system log directory. This represents the logs of the VM hosting docker. Consumed by the filebeat system module.
      - /var/log/:/var/log/host/:ro
      #Mount the docker logs for indexing by the custom prospector ./config/filebeat/prospectors.d
      - /var/lib/docker/containers:/hostfs/var/lib/docker/containers
      #Named volume fsdata. This is used to persist the registry file between restarts, so to avoid data duplication
      - filebeat-data:/usr/share/filebeat/data/
    networks:
    - logging
    command: filebeat -e -E output.elasticsearch.username=elastic -E output.elasticsearch.password=${ES_PASSWORD:-changeme} -strict.perms=false
#    restart: on-failure
    depends_on:
      #wait for the these services to come up. This ensures the logs are available and ES exists for indexing
      - elasticsearch
#      :  { condition: service_healthy }
      - nginx
#      : { condition: service_started }
      - apache2
#      : { condition: service_started }
    deploy:
      mode: global
      restart_policy:
        condition: on-failure
      labels:
      - com.df.notify=true
      - com.df.distribute=true
      - com.df.alertName=memlimit
      - com.df.alertIf=@service_mem_limit:0.8
      - com.df.alertFor=30s

  #Metricbeat container
  metricbeat:
#    container_name: metricbeat
    hostname: metricbeat
    user: root
    image: docker.elastic.co/beats/metricbeat:${ELASTIC_VERSION:-5.5.1}
    configs:
    #Mount the metricbeat configuration so users can make edit
    - source: metricbeat_config
      target: /usr/share/metricbeat/metricbeat.yml
      #Mount the modules.d directory into the container. This allows user to potentially make changes to the modules and they will be dynamically loaded.
    - source: metricbeat_docker_config
      target: /usr/share/metricbeat/modules.d/docker.yml
    - source: metricbeat_system_config
      target: /usr/share/metricbeat/modules.d/system.yml
    volumes:
      # The commented sections below enable Metricbeat to monitor the Docker host rather than the Metricbeat container. These are used by the system module.
      - /proc:/hostfs/proc:ro
      - /sys/fs/cgroup:/hostfs/sys/fs/cgroup:ro
      #Allows us to report on docker from the hosts information
      - /var/run/docker.sock:/var/run/docker.sock
      #We mount the host filesystem so we can report on disk usage with the system module
      - /:/hostfs:ro
    command: metricbeat -e -system.hostfs=/hostfs -E output.elasticsearch.username=elastic -E output.elasticsearch.password=${ES_PASSWORD:-changeme} -strict.perms=false
    networks:
    - logging
#    restart: on-failure
    environment:
      - "MYSQL_ROOT_PASSWORD=${MYSQL_ROOT_PASSWORD:-changeme}"
    depends_on:
      #wait for the these services to come up. This ensures the logs are available and ES exists for indexing
      - elasticsearch
#        :  { condition: service_healthy }
      - nginx
#        : { condition: service_started }
      - apache2
#        : { condition: service_started }
    deploy:
      mode: global
      restart_policy:
        condition: on-failure
      labels:
      - com.df.notify=true
      - com.df.distribute=true
      - com.df.alertName=memlimit
      - com.df.alertIf=@service_mem_limit:0.8
      - com.df.alertFor=30s

  #Packetbeat container
  packetbeat:
#    container_name: packetbeat
    hostname: packetbeat
    image: "docker.elastic.co/beats/packetbeat:${ELASTIC_VERSION:-5.5.1}"
    configs:
    #Mount the filebeat configuration so users can make edit
    - source: packetbeat_config
      target: /usr/share/packetbeat/packetbeat.yml
    # Packetbeat needs some elevated privileges to capture network traffic.
    # We'll grant them with POSIX capabilities.
#    cap_add: ['NET_RAW', 'NET_ADMIN']
    # Use "host mode" networking to allow Packetbeat to capture traffic from
    # the real network interface on the host, rather than being isolated to the
    # container's virtual interface.
#    network_mode: host
    command: packetbeat -e -E output.elasticsearch.hosts='["localhost:9200"]' -E output.elasticsearch.username=elastic -E output.elasticsearch.password=${ES_PASSWORD:-changeme} -strict.perms=false
    depends_on:
      #Wait for ES to be up before we start collecting
      - elasticsearch
#        :  { condition: service_healthy }
    deploy:
      mode: replicated
      replicas: 1
      restart_policy:
        condition: on-failure
      labels:
      - com.df.distribute=true
      - com.df.notify=true
      - com.df.port=80
      - com.df.alertName=memlimit
      - com.df.alertIf=@service_mem_limit:0.8
      - com.df.alertFor=30s

  #Configure Stack container. This short lived container configures the stack once Kibana and Elasticsearch are available. More specifically, using a script it sets passwords, import dashboards, sets a default index pattern, loads templates and pipelines
  configure_stack:
#    container_name: configure_stack
    image: docker.elastic.co/beats/metricbeat:${ELASTIC_VERSION:-5.5.1}
    configs:
    - source: configure-stack
      target: /usr/local/bin/configure-stack.sh
#      read-only
    - source: pipelines
      target: /usr/local/bin/pipelines/docker-logs.json
    - source: templates
      target: /usr/local/bin/templates/docker-logs.json
#    volumes: ['./init/configure-stack.sh:/usr/local/bin/configure-stack.sh:ro','./init/pipelines/:/usr/local/bin/pipelines/','./init/templates/:/usr/local/bin/templates/']
    command: ['/bin/bash', '-c', 'cat /usr/local/bin/configure-stack.sh | tr -d "\r" | bash']
    networks:
    - logging
    environment: ['ELASTIC_VERSION=${ELASTIC_VERSION:-5.5.1}','ES_PASSWORD=${ES_PASSWORD:-changeme}','DEFAULT_INDEX_PATTERN=${DEFAULT_INDEX_PATTERN:-metricbeat-*}']
    depends_on:
    - elasticsearch
    - kibana
    deploy:
      replicas: 1
      update_config:
        parallelism: 1
        delay: 10s
      restart_policy:
        condition: none

volumes:
  elasticsearch-data:
    external: true
  filebeat-data:
    driver: local

configs:
  configure-stack:
    file: ./init/configure-stack.sh
  pipelines:
    file: ./init/pipelines/docker-logs.json
  templates:
    file: ./init/templates/docker-logs.json
  elastic_config:
    file: ./config/elasticsearch/elasticsearch.yml
  kibana_config:
    file: ./config/kibana/kibana.yml
  heartbeat_config:
    file: ./config/beats/heartbeat/heartbeat.yml
  filebeat_config:
    file: ./config/beats/filebeat/filebeat.yml
  prospectors_config:
    file: ./config/beats/filebeat/prospectors.d/docker.yml
  packetbeat_config:
    file: ./config/beats/packetbeat/packetbeat.yml
  metricbeat_config:
    file: ./config/beats/metricbeat/metricbeat.yml
  metricbeat_docker_config:
    file: ./config/beats/metricbeat/modules.d/docker.yml
  metricbeat_system_config:
    file: ./config/beats/metricbeat/modules.d/system.yml

networks:
  default:
    driver: overlay
  proxy:
    external: true
  logging:
    external: true
